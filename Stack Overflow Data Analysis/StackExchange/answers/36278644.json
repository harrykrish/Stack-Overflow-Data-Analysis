{"title": "Do you benefit from the Kryo serializer when you use Pyspark?", "tags": ["apache-spark", "pyspark", "kryo"], "creation_date": 1459238486, "score": 4, "body": "<p><code>Kryo</code> won\u2019t make a major impact on <code>PySpark</code> because it just stores data as <code>byte[]</code> objects, which are fast to serialize even with Java. </p>\n\n<p>But it may be worth a try \u2014 you would just set <code>spark.serializer</code> and not try to register any classes. What might make more impact is storing data as <code>MEMORY_ONLY_SER</code> and turning on <code>spark.rdd.compress</code>, which will compress them. In Java this can add some CPU overhead but Python runs quite a bit slower so it might not matter, and it might speed stuff up by reducing GC or letting you cache more data.</p>\n\n<p>Reference : <a href=\"http://apache-spark-user-list.1001560.n3.nabble.com/using-Kryo-with-pyspark-td4229.html\" rel=\"nofollow\">Matei Zaharia's answer</a> in the mailing list.</p>\n", "last_activity_date": 1459238804, "answer_id": 36278644, "is_accepted": true, "owner": {"user_id": 3415409, "reputation": 11134, "user_type": "registered", "accept_rate": 87, "display_name": "eliasah", "link": "http://stackoverflow.com/users/3415409/eliasah", "profile_image": "https://i.stack.imgur.com/upS8b.jpg?s=128&g=1"}, "last_edit_date": 1459238804, "question_id": 36278574}