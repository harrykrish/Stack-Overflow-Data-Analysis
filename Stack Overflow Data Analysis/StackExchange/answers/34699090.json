{"body": "<p>Your use case is a little unusual. Cassandra is intended more for transactional operations on a small number of rows rather than doing bulk processing like you might do in hadoop.</p>\n\n<p>The way you are doing your query, you are accessing one partition on a single node and transferring the 100K rows to your client. That's a lot of data to move across the network and I'm not sure why you would want to do that. You're doing everything sequentially, so you're getting no parallelism or benefit from having three nodes.</p>\n\n<p>Usually if you want to do bulk processing on a lot of rows in Cassandra, you'd use Spark to do distributed processing on each node rather than sequentially fetch a lot of data to a client.</p>\n\n<p>Also the two indexes you are creating don't look like they will work very well. Cassandra indexes are intended for fields that have a low cardinality, but you appear to be creating indexes on high cardinality fields. Cassandra indexes are very different from indexes in relational databases.</p>\n\n<p>I'd have to see you client code to know if you are doing something inefficiently there. Usually fetching a lot of rows would trigger paging, so I'm not sure how you're handling that.</p>\n", "tags": ["mysql", "cassandra"], "creation_date": 1452374511, "score": 1, "last_activity_date": 1452374511, "answer_id": 34699090, "is_accepted": true, "owner": {"user_id": 4339776, "reputation": 5456, "user_type": "registered", "accept_rate": 57, "display_name": "Jim Meyer", "link": "http://stackoverflow.com/users/4339776/jim-meyer", "profile_image": "https://www.gravatar.com/avatar/ae7fe21641bf0e0f070c011b391fe700?s=128&d=identicon&r=PG&f=1"}, "title": "Why is my Cassandra Database too slow in reading data? Want to read 100,000 rows in less than 10s", "question_id": 34691462}