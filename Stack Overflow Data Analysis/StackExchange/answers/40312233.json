{"body": "<p>Almost 2 months later but I thought it might help others if I post something I got to:</p>\n\n<p><a href=\"http://zachmoshe.com/2016/09/26/efficient-range-joins-with-spark.html\" rel=\"nofollow\">http://zachmoshe.com/2016/09/26/efficient-range-joins-with-spark.html</a></p>\n\n<p>It basically a more efficient implementation of range-join between two DataSets based on a Timestamp or a Numeric field (Scala, with Spark 2.0).</p>\n", "tags": ["pyspark", "apache-spark-sql"], "creation_date": 1477683930, "score": 0, "last_activity_date": 1477683930, "answer_id": 40312233, "is_accepted": true, "owner": {"user_id": 1643257, "reputation": 758, "user_type": "registered", "accept_rate": 67, "display_name": "Zach Moshe", "link": "http://stackoverflow.com/users/1643257/zach-moshe", "profile_image": "https://i.stack.imgur.com/s5qJB.jpg?s=128&g=1"}, "title": "How to efficiently join 2 DateFrames based on Timestamp difference?", "question_id": 39295423}