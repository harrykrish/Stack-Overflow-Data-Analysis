{"title": "Transform RDD in PySpark", "tags": ["apache-spark", "rdd"], "creation_date": 1461759559, "score": 3, "body": "<p>Here is a solution :</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>data = [((0, 0), 0), ((0, 1), 0), ((1, 0), 0), ((1, 1), 0)]\nrdd = sc.parallelize(data)\nrdd2 = rdd.map(lambda ((i, j), _): ((i, j), 1) if (i == j) else ((i, j), 0))\nrdd2.collect()\n# [((0, 0), 1), ((0, 1), 0), ((1, 0), 0), ((1, 1), 1)]\n</code></pre>\n\n<p>You can also define a cleaner solution by using a function on the mapper : </p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def transformation(entry):\n    (i, j), v = entry\n    return (i, j), v + 1 if i == j else 0\n\nrdd3 = rdd.map(transformation)\nrdd3.collect()\n# [((0, 0), 1), ((0, 1), 0), ((1, 0), 0), ((1, 1), 1)]\n</code></pre>\n", "last_activity_date": 1461784312, "answer_id": 36889639, "is_accepted": true, "owner": {"user_id": 3415409, "reputation": 11134, "user_type": "registered", "accept_rate": 87, "display_name": "eliasah", "link": "http://stackoverflow.com/users/3415409/eliasah", "profile_image": "https://i.stack.imgur.com/upS8b.jpg?s=128&g=1"}, "last_edit_date": 1461784312, "question_id": 36888746}