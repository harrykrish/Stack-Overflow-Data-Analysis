{"body": "<p>The article is only scratching the surface, and gets some things wrong (or at least questionable), but the overall outcome is usually about the same: linked lists are much slower.</p>\n\n<p>One thing to note is that \"nodes are stored incontiguously [sic]\" is an overly strong claim. It is true that in general nodes returned by, for example, <code>malloc</code> may be spread around in memory, especially if nodes are allocated at different times or from different threads. However, in practice, many nodes are often allocated on the same thread, at the same time, and these will often end up quite contiguous in memory, because good <code>malloc</code> implementations are, well, good! Furthermore, when performance is a concern, you may often use special allocators on a per-object basis, which allocated the fixed-sized notes from one or more contiguous chunks of memory, which will provide great spatial locality.</p>\n\n<p>So you can assume that in at least some scenarios, linked lists will give you reasonable to good spatial locality. It largely depends on if you are adding most of all of your list elements at once (linked lists do OK), or are constantly adding elements over a longer period of time (linked lists will have poor spatial locality).</p>\n\n<p>Now, on the side of lists being slow, one of the main issues glossed over with linked lists is the large constant factors associated with some operations relative to the array variant. Everyone knows that accessing an element given its index is <code>O(n)</code> in a linked list and <code>O(1)</code> in an array, so you don't use the linked list if you are going to do a lot of accesses by index. Similarly, everyone knows that adding an element to the middle of a list takes <code>O(1)</code> time in a linked list, and <code>O(n)</code> time in an array, so the former wins in that scenario.</p>\n\n<p>What they don't address is that even operations that have the same algorithmic complexity can be <em>much</em> slower in practice in one implementation...</p>\n\n<p>Let's take iterating over all the elements in a list (looking for a particular value, perhaps). That's an <code>O(n)</code> operation regardless if you use a linked or array representation. So it's a tie, right?</p>\n\n<p>Not so fast! The actual performance can vary a lot! <a href=\"https://godbolt.org/g/LjXb5U\" rel=\"nofollow\">Here is what</a> typical <code>find()</code> implementations would look like when compiled at <code>-O2</code> optimization level in x86 gcc, thanks to godbolt which makes this easy.</p>\n\n<h2>Array</h2>\n\n<h3>C Code</h3>\n\n<pre><code>int find_array(int val, int *array, unsigned int size) {\n    for (unsigned int i=0; i &lt; size; i++) {\n      if (array[i] == val)\n        return i;\n    }\n\n    return -1;\n}\n</code></pre>\n\n<h3>Assembly (loop only)<sup>1</sup></h3>\n\n<pre><code>.L6:\n        add     rsi, 4\n        cmp     DWORD PTR [rsi-4], edi\n        je      .done\n        add     eax, 1\n        cmp     edx, eax\n        jne     .notfound\n</code></pre>\n\n<h2>Linked List</h2>\n\n<h3>C Code</h3>\n\n<pre><code>struct Node {\n  struct Node *next;\n  int item;\n};\n\nNode * find_list(int val, Node *listptr) {\n    while (listptr) {\n      if (listptr-&gt;item == val)\n        return listptr;\n      listptr = listptr-&gt;next;\n    }\n    return 0;\n}\n</code></pre>\n\n<h3>Assembly (loop only)</h3>\n\n<pre><code>.L20:\n        cmp     DWORD PTR [rax+8], edi\n        je      .done\n        mov     rax, QWORD PTR [rax]\n        test    rax, rax\n        jne     .notfound\n</code></pre>\n\n<p>Just eyeballing the C code, both methods look competitive. The array method is going to have an increment of <code>i</code>, a couple of comparisons, and one memory access to read the value from the array. The linked list version if going to have a couple of (adjacent) memory accesses to read the <code>Node.val</code> and <code>Node.next</code> members, and a couple of comparisons.</p>\n\n<p>The assembly seems to bear that out: the linked list version has 5 instructions and the array version<sup>2</sup> has 6. All of the instructions are simple ones that have a throughput of 1 per cycle or more on modern hardware.</p>\n\n<p>If you test it though - <em>with both lists fully resident in L1</em>, you'll find that the array version executes at about 1.5 cyles per iteration, while the linked list version takes about 4! That's because the linked list version is limited by it's loop-carried dependency on <code>listptr</code>. The one line <code>listptr = listptr-&gt;next</code> boils down to on instruction, but that one instruction will never execute more than once every 4 cycles, because each execution depends on the completion of the prior one (you need to finish reading <code>listptr-&gt;next</code> before you can calculate <code>listptr-&gt;next-&gt;next</code>). Even though modern CPUs can execute something like 2 loads cycles every cycle, these loads take ~4 cycles to complete, so you get a serial bottleneck here.</p>\n\n<p>The array version also has loads, but the address doesn't depend on the prior load:</p>\n\n<pre><code>add     rsi, 4\ncmp     DWORD PTR [rsi-4], edi\n</code></pre>\n\n<p>It depends only on <code>rsi</code>, which is simply calculated by adding 4 each iteration. An <code>add</code> has a latency of one cycle on modern hardware, so this doesn't create a bottleneck (unless you get below 1 cycle/iteration). So the array loop is able to use the full power of the CPU, executing many instructions in parallel. The linked list version is not.</p>\n\n<p>This isn't unique to \"find\" - any operation linked that needs to iterate over many elements will have this <em>pointer chasing</em> behavior, which is inherently slow on modern hardware. </p>\n\n<hr>\n\n<p><sup>1</sup>I omitted the epilogue and prologue for each assembly function because it really isn't doing anything interesting. Both versions had no epilogue at all really, and the proloque was very similar for both, peeling off the first iteration and jumping into the middle of the loop. The full code is <a href=\"https://godbolt.org/g/LjXb5U\" rel=\"nofollow\">available for inspection</a> in any case.</p>\n\n<p><sup>2</sup>It's worth noting that gcc didn't really do as well as it could have here, since it maintains both <code>rsi</code> as the pointer into the array, and <code>eax</code> as the index <code>i</code>. This means two separate <code>cmp</code> instructions, and two increments. Better would have been to maintain only the pointer <code>rsi</code> in the loop, and to compare against <code>(array + 4*size)</code> as the \"not found\" condition. That would eliminate one increment. Additionally, you could eliminate one <code>cmp</code> by having <code>rsi</code> run from <code>-4*size</code> up to zero, and indexing into array using <code>[rdi + rsi]</code> where rdi is <code>array + 4*size</code>. Shows that even today optimizing compilers aren't getting everything right!</p>\n", "tags": ["c", "caching", "optimization", "linked-list", "cpu-cache"], "creation_date": 1476732555, "score": 1, "last_activity_date": 1476732555, "answer_id": 40094200, "is_accepted": false, "owner": {"user_id": 149138, "reputation": 6036, "user_type": "registered", "accept_rate": 67, "display_name": "BeeOnRope", "link": "http://stackoverflow.com/users/149138/beeonrope", "profile_image": "https://www.gravatar.com/avatar/cfd457233c8ebbab383475fc097442d9?s=128&d=identicon&r=PG"}, "title": "CPU Cache disadvantages of using linked lists in C", "question_id": 40071635}